{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Source Implementation of Snapchat Photo Filters with Python and Opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our goal is to buid an application that enables users to apply filters to their images. We intend to create this application with open source tools such as Python and OpenCV. Specifically, our application will place a mask on the user's face in real-time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV (Open Source Computer Vision) is a library of programming functions mainly aimed at real-time computer vision. Originally developed by Intel's research center in Nizhny Novgorod (Russia), it was later supported by Willow Garage and is now maintained by Itseez.\n",
    "\n",
    "https://en.wikipedia.org/wiki/OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapchat Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapchat enables users to apply masks to their faces in real time, and to save snapshots of their masks to share with the world. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Ahnold](http://forum.nutrimuscle.com/hebergeur_images/Upload/images/snapchat.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not investigate specifically how Snapchat does this; we only investigated doing this ourselves. Nevertheless, it appears that the application will require solving several different problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the webcam to capture images in real-time\n",
    "- Facial recognition\n",
    "- Facial landmark recognition (for mask placement)\n",
    "- Mask placement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the webcam with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below works well to capture video from the webcam. The code is directly from the OpenCV documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV exposes an API that allows users to train an object recognition model using Haar feature-based classifiers using the techniques in \"Rapid Object Detection using a Boosted Cascade of Simple Features\" (Viola, Jones, 2001). We use use it to construct our model for facial recognition. \n",
    "\n",
    "#### Haar Classifiers\n",
    "\n",
    "Haar feature-based classification uses Adaboost to distinguish between important and irrelevant features in images. It also uses a Cascade of Classifiers method to quickly discard pieces of images where it detects no important features. \n",
    "\n",
    "http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need samples faces to train a model for facial recognition. They are used by the boosting process to define what the model should actually look for when trying to find your objects of interest. \n",
    "\n",
    "http://docs.opencv.org/trunk/dc/d88/tutorial_traincascade.html\n",
    "\n",
    "We downloaded a dataset of over 13,000 faces from Labeled Faces in the Wild, a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set.:\n",
    "\n",
    "http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
    "\n",
    "![sample](Desktop/cv/faces/Aaron_Eckhart/Aaron_Eckhart_0001.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the positive images have dimensions 250x250."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the negative samples as background noise and as examples of what *not* to recognize in an image. We downloaded a set of about 4000 negative samples from:\n",
    "\n",
    "https://github.com/sonots/tutorial-haartraining/tree/master/data/negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the photos is a basic background image that looks like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sample](Desktop/cv/negative_images/neg-0002.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the negative images have dimensions 640x480."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing 150 Random Faces for Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to train a model with 150 faces chosen randomly from the 13,000 face database. The following code chooses 150 random faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, random, shutil\n",
    "file_list = []\n",
    "for i in range(1,151):\n",
    "    random_file = random.choice(os.listdir('/cv/positive_images/'))\n",
    "    source = '/cv/positive_images/' + random_file\n",
    "    new_path = '/cv/train_faces/' + random_file\n",
    "    os.rename(source, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing 1000 Random Negatives for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, random, shutil\n",
    "file_list = []\n",
    "for i in range(1,1001):\n",
    "    random_file = random.choice(os.listdir('/Users/jaguirre/Desktop/cv/negative_images/'))\n",
    "    source = '/Users/jaguirre/Desktop/cv/negative_images/' + random_file\n",
    "    new_path = '/Users/jaguirre/Desktop/cv/train_negatives/' + random_file\n",
    "    os.rename(source, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To point OpenCV to the list of negative files, we can easily create a list like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ls *.jpg > negatives.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV Functions for Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the OpenCV API offers several utilities to facilitate model learning. We'll be using 3 of them:\n",
    "- opencv_annotation\n",
    "-- This function allows you identify objects in images and creates a text file of the location of the object within the image\n",
    "- opencv_createsamples\n",
    "-- This function creates samples by which to train your model\n",
    "- opencv_traincascade\n",
    "-- This function trains the model and uses several parameters for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the following code to annotate the faces in the 150 randomly selected files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opencv_annotation -images ~/Desktop/cv/test_faces/ -annotations ~/Desktop/cv/annotations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this command opens up each image in the directory for you to manually identify the target object.\n",
    "\n",
    "![object recognition](http://christopher5106.github.io/img/rectangle_format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV CreateSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a positive sample set where the face images are superimposed onto the negative samples with the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opencv_createsamples -num 149 -vec test_vec.vec -info annotations.txt -bg negatives.txt -w 250 -h 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got parse errors during this step; it's important to check the annotations.txt file to make sure that the number of points corresponds to the number of boxes in the images. If they do not correspond, they need to be edited manually. For example, if an image has 3 bounded boxes for 3 target objects, there should be 12 points associated with the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV TrainCascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train a model to detect our target object with the following command:\n",
    "\n",
    "opencv_traincascade -data ~/Desktop/cv/cascades -vec test_vec.vec -bg negatives.txt -featureType LBP -numPos 126 -acceptanceRatioBreakValue .00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our model with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#cascPath = sys.argv[1]\n",
    "faceCascade = cv2.CascadeClassifier(\"cascades/cascade.xml\")\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=4,\n",
    "        minSize=(22, 22),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test on a picture\n",
    "\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('/Users/jaguirre/Desktop/cv/cascades/cascade.xml')\n",
    "#eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml') \n",
    "img = cv2.imread('/Users/jaguirre/Desktop/cv/train_faces/Brenda_Magana_0001.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    #eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    #for (ex,ey,ew,eh) in eyes:\n",
    "    #    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2) \n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

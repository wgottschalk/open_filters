{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2  # OpenCV Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "#       Load and configure Haar Cascade Classifiers\n",
    "#-----------------------------------------------------------------------------\n",
    " \n",
    "# location of OpenCV Haar Cascade Classifiers:\n",
    "#baseCascadePath = \"OpenCV/haarcascades/\"\n",
    " \n",
    "# xml files describing our haar cascade classifiers\n",
    "faceCascadeFilePath = \"haarcascade_frontalface_default.xml\"\n",
    "noseCascadeFilePath = \"haarcascade_mcs_nose.xml\" ## need to download this and put it in local (same with face)\n",
    " \n",
    "# build our cv2 Cascade Classifiers\n",
    "faceCascade = cv2.CascadeClassifier(faceCascadeFilePath)\n",
    "noseCascade = cv2.CascadeClassifier(noseCascadeFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "#       Load and configure mustache (.png with alpha transparency)\n",
    "#-----------------------------------------------------------------------------\n",
    " \n",
    "# Load our overlay image: mustache.png\n",
    "imgMustache = cv2.imread('mustache.png',-1)\n",
    " \n",
    "# Create the mask for the mustache\n",
    "orig_mask = imgMustache[:,:,3]\n",
    " \n",
    "# Create the inverted mask for the mustache\n",
    "orig_mask_inv = cv2.bitwise_not(orig_mask)\n",
    " \n",
    "# Convert mustache image to BGR\n",
    "# and save the original image size (used later when re-sizing the image)\n",
    "imgMustache = imgMustache[:,:,0:3]\n",
    "origMustacheHeight, origMustacheWidth = imgMustache.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "#       Main program loop\n",
    "#-----------------------------------------------------------------------------\n",
    " \n",
    "# collect video input from first webcam on system\n",
    "video_capture = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "    # Capture video feed\n",
    "    ret, frame = video_capture.read()\n",
    " \n",
    "    # Create greyscale image from the video feed\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Detect faces in input video stream\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags = 0\n",
    "        #flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        #flags=cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    "    )\n",
    " \n",
    "   # Iterate over each face found\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Un-comment the next line for debug (draw box around all faces)\n",
    "        # face = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    " \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    " \n",
    "        # Detect a nose within the region bounded by each face (the ROI)\n",
    "        nose = noseCascade.detectMultiScale(roi_gray)\n",
    " \n",
    "        for (nx,ny,nw,nh) in nose:\n",
    "            # Un-comment the next line for debug (draw box around the nose)\n",
    "            #cv2.rectangle(roi_color,(nx,ny),(nx+nw,ny+nh),(255,0,0),2)\n",
    " \n",
    "            # The mustache should be three times the width of the nose\n",
    "            mustacheWidth =  3 * nw\n",
    "            mustacheHeight = mustacheWidth * origMustacheHeight / origMustacheWidth\n",
    " \n",
    "            # Center the mustache on the bottom of the nose\n",
    "            x1 = int(nx - (mustacheWidth/4))  ## changed these all to int because was float error\n",
    "            x2 = int(nx + nw + (mustacheWidth/4))\n",
    "            y1 = int(ny + nh - (mustacheHeight/2))\n",
    "            y2 = int(ny + nh + (mustacheHeight/2))\n",
    " \n",
    "            # Check for clipping\n",
    "            if x1 < 0:\n",
    "                x1 = 0\n",
    "            if y1 < 0:\n",
    "                y1 = 0\n",
    "            if x2 > w:\n",
    "                x2 = w\n",
    "            if y2 > h:\n",
    "                y2 = h\n",
    " \n",
    "            # Re-calculate the width and height of the mustache image\n",
    "            mustacheWidth = x2 - x1 \n",
    "            mustacheHeight = y2 - y1\n",
    " \n",
    "            # Re-size the original image and the masks to the mustache sizes\n",
    "            # calcualted above\n",
    "            mustache = cv2.resize(imgMustache, (mustacheWidth,mustacheHeight), interpolation = cv2.INTER_AREA)\n",
    "            mask = cv2.resize(orig_mask, (mustacheWidth,mustacheHeight), interpolation = cv2.INTER_AREA)\n",
    "            mask_inv = cv2.resize(orig_mask_inv, (mustacheWidth,mustacheHeight), interpolation = cv2.INTER_AREA)\n",
    " \n",
    "            # take ROI for mustache from background equal to size of mustache image\n",
    "            roi = roi_color[y1:y2, x1:x2]\n",
    " \n",
    "            # roi_bg contains the original image only where the mustache is not\n",
    "            # in the region that is the size of the mustache.\n",
    "            roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    " \n",
    "            # roi_fg contains the image of the mustache only where the mustache is\n",
    "            roi_fg = cv2.bitwise_and(mustache,mustache,mask = mask)\n",
    " \n",
    "            # join the roi_bg and roi_fg\n",
    "            dst = cv2.add(roi_bg,roi_fg)\n",
    " \n",
    "            # place the joined image, saved to dst back over the original image\n",
    "            roi_color[y1:y2, x1:x2] = dst\n",
    " \n",
    "            break\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    " \n",
    "    # press any key to exit\n",
    "    # NOTE;  x86 systems may need to remove: \"0xFF == ord('q')\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
